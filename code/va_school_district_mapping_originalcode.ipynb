{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shapefile\n",
    "import matplotlib.colors as colors\n",
    "#from matplotlib.patches import Polygon\n",
    "import pandas as pd\n",
    "from shapely.geometry import Polygon\n",
    "from descartes.patch import PolygonPatch \n",
    "import cmocean\n",
    "import matplotlib.cm as cmx\n",
    "from matplotlib.colorbar import ColorbarBase\n",
    "from matplotlib.collections import PatchCollection\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source of the school district shapefiles is from the US Census Bureau but....they have a screw up in their system. Though the UNSD\n",
    "# file is supposed to be all Unified School Districts (thank god they're mostly by county or incorporated city unlike say Arizona), one\n",
    "# unifed school district, Lexington City Schools which has elementary, middle & high school has it's own special shapefile as a\n",
    "# an elementary school district for the Census Bureau. So I just merged the two danged files with pyshp/shapefile and made the shapefile\n",
    "# relevant files with a suffix of _combined\n",
    "# shapefiles are the 2017 versions sourced at https://www.census.gov/geo/maps-data/data/cbf/cbf_sd.html\n",
    "\n",
    "\n",
    "sf = shapefile.Reader('/mnt/c/Users/erinl/Desktop/virginia_census_regions/cb_2017_51_unsd_500k/cb_2017_51_unsd_500k_combined')\n",
    "\n",
    "fields = sf.fields\n",
    "shapes = sf.shapes\n",
    "records = sf.records()\n",
    "\n",
    "\n",
    "def find_column(column_name):\n",
    "    for fieldno in range(len(sf.fields)):\n",
    "        if (sf.fields[fieldno][0] == column_name):\n",
    "            #print(\"Column number: {0} is {1}.f\".format(fieldno, column_name))\n",
    "            return fieldno-1\n",
    " \n",
    "\n",
    "FULLNAME = find_column('NAME')\n",
    "\n",
    "school_districts = []\n",
    "\n",
    "\n",
    "\n",
    "# the common info in all the files is going to be a flavor of school district name. The Census Bureau has a love of labeling everything\n",
    "# <placename> Public Schools, but then the Commonwealth of Virginia just uses <placename>\n",
    "\n",
    "for shapeno in range(len(records)):\n",
    "    schools = records[shapeno][FULLNAME]\n",
    "    district = schools.rstrip(' Public Schools')\n",
    "    school_districts.append(district)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['English: Reading' 'English: Writing' 'History and Social Sciences'\n",
      " 'Mathematics' 'Science'] ['2015-2016', '2016-2017', '2017-2018']\n",
      "Possible student classes ['All Students' 'American Indian' 'Asian' 'Black' 'Hispanic'\n",
      " 'Native Hawaiian' 'White' 'Two or more races'\n",
      " 'Students with Disabilities' 'Economically Disadvantaged'\n",
      " 'English Learners' 'Migrant' 'Foster Care' 'Military Connected' 'Female'\n",
      " 'Male']\n"
     ]
    }
   ],
   "source": [
    "# Now to the Virginia SOLs. Not that the students are shit out of luck, it's Standards of Learning.\n",
    "# Data the state has is on pass rates for the last 3 years. In one case on the state level, in the other case on the district level\n",
    "# Data grabbed from http://www.doe.virginia.gov/statistics_reports/school_report_card/index.shtml#solresults\n",
    "# Note: I did have to edit the district level file, the Commonwealth is not consistent on using a < as the \"not enough students to report\"\n",
    "# and also in some districts they dropped whole classifications. So editting with the assistance of colorful language and a beverage was done\n",
    "\n",
    "sol_state_data = pd.read_csv('/mnt/c/Users/erinl/Desktop/va_school_data/2017-2018-state-subject-area.csv')\n",
    "unique_exams = sol_state_data.Subject.unique()\n",
    "\n",
    "\n",
    "print (unique_exams, unique_years)\n",
    "\n",
    "student_types = sol_state_data.Subgroup.unique()\n",
    "print ('Possible student classes', student_types)\n",
    "\n",
    "\n",
    "\n",
    "sol_district_data = pd.read_csv('/mnt/c/Users/erinl/Desktop/va_school_data/2017-2018-division-subject-area.csv')\n",
    "\n",
    "# \"districts\" to drop: 'Virginia School for the Deaf and Blind-Staunton'\n",
    "# 'Quantico Marine Corps Center School District' and 'Dahlgren Department of Defense School District'\n",
    "# because functionally for the map they don't exist\n",
    "deaf_and_blind_drop = sol_district_data[sol_district_data['Div Name'] == 'Virginia School for the Deaf and Blind-Staunton'].index\n",
    "sol_district_data.drop(deaf_and_blind_drop , inplace=True)\n",
    "\n",
    "quantico_drop = sol_district_data[sol_district_data['Div Name'] == 'Quantico Marine Corps Center School District'].index\n",
    "sol_district_data.drop(quantico_drop, inplace=True)\n",
    "\n",
    "dahlgren_drop = sol_district_data[sol_district_data['Div Name'] == 'Dahlgren Department of Defense School District'].index\n",
    "sol_district_data.drop(dahlgren_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:22: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No State SOL data for Quantico Marine Corps Center School District\n",
      "No State SOL data for Dahlgren Department of Defense School District\n",
      "No State SOL data for Quantico Marine Corps Center School District\n",
      "No State SOL data for Dahlgren Department of Defense School District\n",
      "No State SOL data for Quantico Marine Corps Center School District\n",
      "No State SOL data for Dahlgren Department of Defense School District\n",
      "No State SOL data for Quantico Marine Corps Center School District\n",
      "No State SOL data for Dahlgren Department of Defense School District\n",
      "No State SOL data for Quantico Marine Corps Center School District\n",
      "No State SOL data for Dahlgren Department of Defense School District\n",
      "No State SOL data for Quantico Marine Corps Center School District\n",
      "No State SOL data for Dahlgren Department of Defense School District\n",
      "No State SOL data for Quantico Marine Corps Center School District\n",
      "No State SOL data for Dahlgren Department of Defense School District\n",
      "No State SOL data for Quantico Marine Corps Center School District\n",
      "No State SOL data for Dahlgren Department of Defense School District\n",
      "No State SOL data for Quantico Marine Corps Center School District\n",
      "No State SOL data for Dahlgren Department of Defense School District\n",
      "No State SOL data for Quantico Marine Corps Center School District\n",
      "No State SOL data for Dahlgren Department of Defense School District\n",
      "No State SOL data for Quantico Marine Corps Center School District\n",
      "No State SOL data for Dahlgren Department of Defense School District\n",
      "No State SOL data for Quantico Marine Corps Center School District\n",
      "No State SOL data for Dahlgren Department of Defense School District\n",
      "No State SOL data for Quantico Marine Corps Center School District\n",
      "No State SOL data for Dahlgren Department of Defense School District\n",
      "No State SOL data for Quantico Marine Corps Center School District\n",
      "No State SOL data for Dahlgren Department of Defense School District\n",
      "No State SOL data for Quantico Marine Corps Center School District\n",
      "No State SOL data for Dahlgren Department of Defense School District\n"
     ]
    }
   ],
   "source": [
    "# time to loop thru Subject and testing year\n",
    "# So up above we printed out all the state test options  and those are:\n",
    "# English: Reading, English: Writing, Mathematics, Science, History and Social Sciences\n",
    "# So, have now written this so you can pick whichever student class you want which I printed up top too\n",
    "# but for now the place holder is 'All Students'\n",
    "\n",
    "unique_years = ['2015-2016', '2016-2017','2017-2018']\n",
    "\n",
    "for subject in range(len(unique_exams)):\n",
    "    for year in range(len(unique_years)):\n",
    "\n",
    "        topic = unique_exams[subject]\n",
    "        test_year = unique_years[year]\n",
    "        group = 'All Students'\n",
    "\n",
    "        state_test = sol_state_data.loc[(sol_state_data['Subgroup'] == group) & (sol_state_data['Subject'] == topic)]\n",
    "        state_value = np.float_(state_test[test_year+' Pass Rate'])\n",
    "\n",
    "        district_test = sol_district_data.loc[(sol_district_data['Subgroup'] == group) & (sol_district_data['Subject'] == topic)]\n",
    "        school_names = np.array(district_test['Div Name'])\n",
    "        district_value = np.array(district_test[test_year+' Pass Rate'])\n",
    "        district_value[district_value == '<'] = np.nan\n",
    "        district_value = np.float_(district_value)\n",
    "\n",
    "\n",
    "# to not totally skew the statistics I do nan out the School for Deaf and Blind\n",
    "#deaf_and_blind = np.where(school_names == 'Virginia School for the Deaf and Blind-Staunton')\n",
    "#district_value[deaf_and_blind] = state_value\n",
    "\n",
    "# okay so of course first test is seeing how the pass rates in individual counties differ from the state value and from district to district\n",
    "        differ_values = district_value - state_value\n",
    "\n",
    "\n",
    "# set the plotting color interval. Since Colormaps run from 0 to 1 and the center of a diverging colormap is at a value of 0.5\n",
    "# I use the max deviation from the state's passing rate and then construct a linear interval\n",
    "# of course this means the extreme colors in the color map only show up in the underperforming side of things since\n",
    "# the state passing rates are in practice > 70%, but again, good enough for hacky farting around\n",
    "        interval = (1/(np.nanmax(np.abs(differ_values))))/2\n",
    "        icolor = 0.5 * np.ones(len(differ_values))\n",
    "        icolor = icolor +differ_values*interval\n",
    "\n",
    "\n",
    "\n",
    "# release the hounds! Oh wait...start the plotting\n",
    "# I go through the plot and basically \"draw\" it, then add a patch for each district in the loop. I'm not sure if the loop is the most \n",
    "# efficient (Hi, girl who originally learned Fortran77 here), but it works\n",
    "\n",
    "        fig, ax1 = plt.subplots(figsize=(20,10))\n",
    "        ax1 = plt.axes() # add the axes\n",
    "        ax1.set_aspect('equal')\n",
    "\n",
    "\n",
    "        mypatches = []\n",
    "\n",
    "        i = 0\n",
    "\n",
    "        for shape in list(sf.iterShapes()):\n",
    "    \n",
    "            district = np.array(school_districts[i])\n",
    "    \n",
    "    # Okay so I discovered some other districts aren't named appropriately in the Census file, le argh \n",
    "    # Also Williamsburg City and James County and Emporia City and Greenville County have a cooperative\n",
    "    # operating agreement in place, so their state scores get reported as the combined district\n",
    "    \n",
    "            if (district == 'Colonial Beach Town'):\n",
    "                district = 'Colonial Beach'\n",
    "            if (district == 'James City County'):\n",
    "                district = 'Williamsburg-James City County'\n",
    "            if (district == 'Williamsburg City'):\n",
    "                district = 'Williamsburg-James City County'\n",
    "            if (district == 'West Point Town'):\n",
    "                district = 'West Point'\n",
    "            if (district == 'Fairfax City'):\n",
    "                district = 'Fairfax County'\n",
    "            if (district == 'Emporia City'):\n",
    "                district = 'Greensville County'\n",
    "   \n",
    "            array_match, = np.where(district == school_names)\n",
    "     \n",
    "    \n",
    "            if (len(array_match) == 1):\n",
    "                this_color= icolor[array_match][0]\n",
    "            if (len(array_match) == 0):\n",
    "        # Okay so there are two districts in the shapefile with no state testing data: the DoD schools\n",
    "        # this is a bit of an unneeded relic, but I want to make sure I'm not neglecting any district in the shapefile\n",
    "                this_color= 0\n",
    "                print ('No State SOL data for', district)\n",
    "    \n",
    "            nparts = len(shape.parts) # total parts\n",
    "            if nparts == 1:\n",
    "                polygon = Polygon(shape.points)\n",
    "                patch = PolygonPatch(polygon, facecolor=plt.cm.seismic(this_color), zorder=2, ec='0.5')\n",
    "                ax1.add_patch(patch)\n",
    "                mypatches.append(patch)\n",
    "\n",
    "            else: # loop over parts of each shape, plot separately \n",
    "                for ip in range(nparts): # loop over parts, plot separately\n",
    "                    i0=shape.parts[ip]\n",
    "                    if ip < nparts-1:\n",
    "                        i1 = shape.parts[ip+1]-1\n",
    "                    else:\n",
    "                        i1 = len(shape.points)\n",
    "\n",
    "                    polygon = Polygon(shape.points[i0:i1+1])\n",
    "                    patch = PolygonPatch(polygon, facecolor=plt.cm.seismic(this_color), zorder=2, ec='0.5')\n",
    "                    ax1.add_patch(patch)\n",
    "                    mypatches.append(patch)\n",
    "\n",
    "            i = i + 1\n",
    "    \n",
    "# okay I want to mark on a colorbar where the most over- and most under- performing school happen to be, esp relative\n",
    "# to the state average and want to label which counties those happen to me\n",
    "\n",
    "        over_district = np.where(differ_values == np.nanmax(differ_values))\n",
    "        under_district, = np.where(differ_values == np.nanmin(differ_values))\n",
    "\n",
    "        over_district_tick = icolor[over_district][0]\n",
    "        under_district_tick = icolor[under_district][0]\n",
    "\n",
    "        over_district_label = school_names[over_district][0]+' '+str(int(district_value[over_district][0]))+'% Pass Rate'\n",
    "        under_district_label = school_names[under_district][0]+' '+str(int(district_value[under_district][0]))+'% Pass Rate'\n",
    "\n",
    "        p = PatchCollection(mypatches, cmap=plt.get_cmap('seismic'), alpha=1.0)\n",
    "        p.set_array([0,0.5,1])\n",
    "#plt.text(-84,35.0, 'Worse')\n",
    "\n",
    "        if (icolor[under_district][0] == 0):\n",
    "            cbar = fig.colorbar(p,orientation='horizontal', ticks=[under_district_tick,0.5,over_district_tick], pad=0.02)\n",
    "            cbar.set_ticklabels([under_district_label,'Whole State '+str(int(state_value))+'% Pass Rate',over_district_label])\n",
    "            cbar.ax.tick_params(labelsize=13)\n",
    "            cbar.outline.set_visible(False)\n",
    "        if ((differ_values[under_district][0] != 0) & (icolor[under_district][0] != 0)):\n",
    "            cbar = fig.colorbar(p,orientation='horizontal', ticks=[0,under_district_tick,0.5,over_district_tick],pad=0.02)\n",
    "            cbar.set_ticklabels(['Under', under_district_label,'Whole State '+str(int(state_value))+'% Pass Rate',over_district_label])\n",
    "            cbar.ax.tick_params(labelsize=13)\n",
    "            cbar.outline.set_visible(False)\n",
    "        if (differ_values[under_district][0] == 0):\n",
    "            cbar = fig.colorbar(p,orientation='horizontal', ticks=[0,under_district_tick,over_district_tick], pad=0.02)\n",
    "            cbar.set_ticklabels(['Under', under_district_label+' '+str(int(state_value))+'% Pass Rate',over_district_label])\n",
    "            cbar.ax.tick_params(labelsize=13)\n",
    "            cbar.outline.set_visible(False)\n",
    "\n",
    "        plt.xlim(-84,-75)\n",
    "        plt.ylim(36.5,39.5)\n",
    "        plt.axis('off')\n",
    "        plt.title(test_year+' '+topic+' Standards of Learning results', fontsize=20)\n",
    "# Oh hey, we can porbably uncomment this next bit when wanting to save the figures, though dpi=180 may be overkill\n",
    "        plt.savefig(topic+'_'+test_year+'.jpg', dpi=50, bbox_inches='tight')\n",
    "        plt.close()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: Reading\n",
      "Male Female\n",
      "No State SOL data for Quantico Marine Corps Center School District\n",
      "No State SOL data for Dahlgren Department of Defense School District\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:28: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "/home/erin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:29: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "/home/erin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:33: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "/home/erin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:34: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: Reading\n",
      "White Black\n",
      "No State SOL data for Quantico Marine Corps Center School District\n",
      "No State SOL data for Dahlgren Department of Defense School District\n",
      "English: Reading\n",
      "White Hispanic\n",
      "No State SOL data for Quantico Marine Corps Center School District\n",
      "No State SOL data for Dahlgren Department of Defense School District\n",
      "English: Reading\n",
      "White Asian\n",
      "No State SOL data for Quantico Marine Corps Center School District\n",
      "No State SOL data for Dahlgren Department of Defense School District\n",
      "English: Reading\n",
      "All Students Economically Disadvantaged\n",
      "No State SOL data for Quantico Marine Corps Center School District\n",
      "No State SOL data for Dahlgren Department of Defense School District\n",
      "English: Writing\n",
      "Male Female\n",
      "No State SOL data for Quantico Marine Corps Center School District\n",
      "No State SOL data for Dahlgren Department of Defense School District\n",
      "English: Writing\n",
      "White Black\n",
      "No State SOL data for Quantico Marine Corps Center School District\n",
      "No State SOL data for Dahlgren Department of Defense School District\n",
      "English: Writing\n",
      "White Hispanic\n",
      "No State SOL data for Quantico Marine Corps Center School District\n",
      "No State SOL data for Dahlgren Department of Defense School District\n",
      "English: Writing\n",
      "White Asian\n",
      "No State SOL data for Quantico Marine Corps Center School District\n",
      "No State SOL data for Dahlgren Department of Defense School District\n",
      "English: Writing\n",
      "All Students Economically Disadvantaged\n",
      "No State SOL data for Quantico Marine Corps Center School District\n",
      "No State SOL data for Dahlgren Department of Defense School District\n",
      "History and Social Sciences\n",
      "Male Female\n",
      "No State SOL data for Quantico Marine Corps Center School District\n",
      "No State SOL data for Dahlgren Department of Defense School District\n",
      "History and Social Sciences\n",
      "White Black\n",
      "No State SOL data for Quantico Marine Corps Center School District\n",
      "No State SOL data for Dahlgren Department of Defense School District\n",
      "History and Social Sciences\n",
      "White Hispanic\n",
      "No State SOL data for Quantico Marine Corps Center School District\n",
      "No State SOL data for Dahlgren Department of Defense School District\n",
      "History and Social Sciences\n",
      "White Asian\n",
      "No State SOL data for Quantico Marine Corps Center School District\n",
      "No State SOL data for Dahlgren Department of Defense School District\n",
      "History and Social Sciences\n",
      "All Students Economically Disadvantaged\n",
      "No State SOL data for Quantico Marine Corps Center School District\n",
      "No State SOL data for Dahlgren Department of Defense School District\n",
      "Mathematics\n",
      "Male Female\n",
      "No State SOL data for Quantico Marine Corps Center School District\n",
      "No State SOL data for Dahlgren Department of Defense School District\n",
      "Mathematics\n",
      "White Black\n",
      "No State SOL data for Quantico Marine Corps Center School District\n",
      "No State SOL data for Dahlgren Department of Defense School District\n",
      "Mathematics\n",
      "White Hispanic\n",
      "No State SOL data for Quantico Marine Corps Center School District\n",
      "No State SOL data for Dahlgren Department of Defense School District\n",
      "Mathematics\n",
      "White Asian\n",
      "No State SOL data for Quantico Marine Corps Center School District\n",
      "No State SOL data for Dahlgren Department of Defense School District\n",
      "Mathematics\n",
      "All Students Economically Disadvantaged\n",
      "No State SOL data for Quantico Marine Corps Center School District\n",
      "No State SOL data for Dahlgren Department of Defense School District\n",
      "Science\n",
      "Male Female\n",
      "No State SOL data for Quantico Marine Corps Center School District\n",
      "No State SOL data for Dahlgren Department of Defense School District\n",
      "Science\n",
      "White Black\n",
      "No State SOL data for Quantico Marine Corps Center School District\n",
      "No State SOL data for Dahlgren Department of Defense School District\n",
      "Science\n",
      "White Hispanic\n",
      "No State SOL data for Quantico Marine Corps Center School District\n",
      "No State SOL data for Dahlgren Department of Defense School District\n",
      "Science\n",
      "White Asian\n",
      "No State SOL data for Quantico Marine Corps Center School District\n",
      "No State SOL data for Dahlgren Department of Defense School District\n",
      "Science\n",
      "All Students Economically Disadvantaged\n",
      "No State SOL data for Quantico Marine Corps Center School District\n",
      "No State SOL data for Dahlgren Department of Defense School District\n"
     ]
    }
   ],
   "source": [
    "# Now to do the comparison within counties/districts version!\n",
    "#so sorry about this but I'm only doing the last reporting year because 3 nested for loops is total pants\n",
    "\n",
    "\n",
    "comp_group1 = ['Male', 'White', 'White', 'White', 'All Students' ]\n",
    "comp_group2 = ['Female', 'Black', 'Hispanic', 'Asian', 'Economically Disadvantaged' ]\n",
    "\n",
    "\n",
    "for subject in range(len(unique_exams)):\n",
    "    for gcount in range(len(comp_group1)):\n",
    "\n",
    "        topic = unique_exams[subject]\n",
    "        print (topic)\n",
    "        test_year = '2017-2018'\n",
    "        \n",
    "        group1 = comp_group1[gcount]\n",
    "        group2 = comp_group2[gcount]\n",
    "        print (group1,group2)\n",
    "\n",
    "\n",
    "\n",
    "        district_group1 = sol_district_data.loc[(sol_district_data['Subgroup'] == group1) & (sol_district_data['Subject'] == topic)]\n",
    "        district_group2  = sol_district_data.loc[(sol_district_data['Subgroup'] == group2) & (sol_district_data['Subject'] == topic)]\n",
    "\n",
    "\n",
    "\n",
    "        district_value1 = np.array(district_group1[test_year+' Pass Rate'])\n",
    "        district_value1[district_value1 == '<'] = np.nan\n",
    "        district_value1[district_value1 == '-'] = np.nan\n",
    "        district_value1 = np.float_(district_value1)\n",
    "\n",
    "        district_value2 = np.array(district_group2[test_year+' Pass Rate'])\n",
    "        district_value2[district_value2 == '<'] = np.nan\n",
    "        district_value2[district_value2 == '-'] = np.nan\n",
    "        district_value2 = np.float_(district_value2)\n",
    "\n",
    "        school_names = np.array(district_group1['Div Name'])\n",
    "\n",
    "#deaf_and_blind = np.where(school_names == 'Virginia School for the Deaf and Blind-Staunton')\n",
    "#district_value1[deaf_and_blind] = np.nan\n",
    "#district_value2[deaf_and_blind] = np.nan\n",
    "\n",
    "\n",
    "        differ_values = district_value1 - district_value2\n",
    "\n",
    "\n",
    "# again, going for linear colorscales buttttt... sometimes the performance can be lopsided, like white kids\n",
    "# always overperforming minorities, so gotta set up an option for both lopsided and variable across the board optiosn\n",
    "\n",
    "        if (np.nanmin(differ_values) < 0):\n",
    "            performance = 'both'\n",
    "            norm_icolor = (differ_values+abs(np.nanmin(differ_values)))/abs(np.nanmax(differ_values) - np.nanmin(differ_values))\n",
    "            colors_midpoint = (0+abs(np.nanmin(differ_values)))/abs(np.nanmax(differ_values) - np.nanmin(differ_values))\n",
    "  \n",
    "\n",
    "        if (np.nanmin(differ_values) >= 0):\n",
    "            performance = 'group1'\n",
    "            norm_icolor = (differ_values-np.nanmin(differ_values))/abs(np.nanmax(differ_values) - np.nanmin(differ_values))\n",
    "            colors_midpoint = (0 +abs(np.nanmin(differ_values)))/abs(np.nanmax(differ_values) - np.nanmin(differ_values))\n",
    "\n",
    "\n",
    "\n",
    "        fig, ax1 = plt.subplots(figsize=(20,10))\n",
    "        ax1 = plt.axes() # add the axes\n",
    "        ax1.set_aspect('equal')\n",
    "\n",
    "\n",
    "        mypatches = []\n",
    "\n",
    "        i = 0\n",
    "\n",
    "        for shape in list(sf.iterShapes()):\n",
    "    \n",
    "            district = np.array(school_districts[i])\n",
    "    \n",
    "            if (district == 'Colonial Beach Town'):\n",
    "                district = 'Colonial Beach'\n",
    "            if (district == 'James City County'):\n",
    "                district = 'Williamsburg-James City County'\n",
    "            if (district == 'Williamsburg City'):\n",
    "                district = 'Williamsburg-James City County'\n",
    "            if (district == 'West Point Town'):\n",
    "                district = 'West Point'\n",
    "            if (district == 'Fairfax City'):\n",
    "                district = 'Fairfax County'\n",
    "            if (district == 'Emporia City'):\n",
    "                district = 'Greensville County'\n",
    "   \n",
    "            array_match, = np.where(district == school_names)\n",
    "    \n",
    "   \n",
    "    \n",
    "            if (len(array_match) == 1):\n",
    "                this_color= norm_icolor[array_match][0]\n",
    "            if (len(array_match) == 0):\n",
    "                this_color= 0\n",
    "                print ('No State SOL data for', district)\n",
    "    \n",
    "    \n",
    "    # okay so one note on colors....if there was no data for a class, the state used < to note that or I added - to the file\n",
    "    # so up above I made those strings into nans. Meaning the differ value of the number of people passing is also then a nan\n",
    "    # so, in the cases where nans are the thing and you can't compare groups, using the Grey color map and a color of 0.5 means\n",
    "    # graying out those counties in the map (sorry y'all)\n",
    "            nparts = len(shape.parts) # total parts\n",
    "            if nparts == 1:\n",
    "                polygon = Polygon(shape.points)\n",
    "                if (np.isfinite(this_color) == True):\n",
    "                    patch = PolygonPatch(polygon, facecolor=plt.cm.BuPu(this_color), zorder=2, ec='0.3', lw=1.3)\n",
    "                if (np.isfinite(this_color) == False):\n",
    "                    patch = PolygonPatch(polygon, facecolor=plt.cm.Greys(0.5), zorder=2, ec='0.8', alpha=0.4)\n",
    "                ax1.add_patch(patch)\n",
    "                mypatches.append(patch)\n",
    "\n",
    "            else: # loop over parts of each shape, plot separately \n",
    "                for ip in range(nparts): # loop over parts, plot separately\n",
    "                    i0=shape.parts[ip]\n",
    "                    if ip < nparts-1:\n",
    "                        i1 = shape.parts[ip+1]-1\n",
    "                    else:\n",
    "                        i1 = len(shape.points)\n",
    "\n",
    "                    polygon = Polygon(shape.points[i0:i1+1])\n",
    "                    if (np.isfinite(this_color) == True):\n",
    "                        patch = PolygonPatch(polygon, facecolor=plt.cm.BuPu(this_color), zorder=2, ec='0.3', lw=1.3)\n",
    "                    if (np.isfinite(this_color) == False):\n",
    "                        patch = PolygonPatch(polygon, facecolor=plt.cm.Greys(0.5), zorder=2, ec='0.8',alpha=0.4)            \n",
    "                    ax1.add_patch(patch)\n",
    "                    mypatches.append(patch)\n",
    "\n",
    "            i = i + 1\n",
    "\n",
    "        over_district = np.where(differ_values == np.nanmax(differ_values))\n",
    "        under_district = np.where(differ_values == np.nanmin(differ_values))\n",
    "\n",
    "        over_district_tick = norm_icolor[over_district][0]\n",
    "        under_district_tick = norm_icolor[under_district][0]\n",
    "\n",
    "\n",
    "\n",
    "        p = PatchCollection(mypatches, cmap=plt.get_cmap('BuPu'), alpha=1.0)\n",
    "        p.set_array([0,0.5,1])\n",
    "\n",
    "        if (performance == 'both'):\n",
    "            over_district_label = str(int(np.nanmax(differ_values)))+'%'+' More '+group1+' pass'\n",
    "            under_district_label = str(int(abs(np.nanmin(differ_values))))+'%'+' More '+group2+' pass'\n",
    "\n",
    "            cbar = fig.colorbar(p,orientation='horizontal', ticks=[under_district_tick,over_district_tick], pad=0.02)\n",
    "            cbar.set_ticklabels([under_district_label,over_district_label])\n",
    "            cbar.ax.tick_params(labelsize=13)\n",
    "            cbar.outline.set_visible(False)\n",
    "    \n",
    "        if (performance == 'group1'):\n",
    "            over_district_label = str(int(np.nanmax(differ_values)))+'%'+' More '+group1+' pass'\n",
    "            under_district_label = str(int(np.nanmin(differ_values)))+'%'+' More '+group2+' pass'\n",
    "\n",
    "            cbar = fig.colorbar(p,orientation='horizontal', ticks=[under_district_tick,over_district_tick], pad=0.02)\n",
    "            cbar.set_ticklabels([under_district_label,over_district_label])\n",
    "            cbar.ax.tick_params(labelsize=13)\n",
    "            cbar.outline.set_visible(False)\n",
    "    \n",
    "\n",
    "        plt.xlim(-84,-75)\n",
    "        plt.ylim(36.5,39.5)\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.title(test_year+' '+topic+' Standards of Learning results', fontsize=20)\n",
    "        plt.savefig(group1+'_vs_'+group2+'_'+topic+'_'+test_year+'.jpg', dpi=180)\n",
    "        plt.close()\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No State SOL data for Quantico Marine Corps Center School District\n",
      "No State SOL data for Dahlgren Department of Defense School District\n",
      "0.4062858453773801 0.029928918817807706\n",
      "['Petersburg City']\n"
     ]
    }
   ],
   "source": [
    "# okay, so via the Census from the SAIPE folks you can get file that gives total students per district and how many in poverty.\n",
    "# it's kinda maybe fixed width, but I just loaded it into Excel and made it a csv.\n",
    "# Original download file here: https://www.census.gov/data/datasets/2016/demo/saipe/2016-school-districts.html\n",
    "\n",
    "poverty = pd.read_csv('/mnt/c/Users/erinl/Desktop/virginia_census_regions/sd16-va.csv', names=['state code', 'district id','district name', \n",
    "                                                                                              'total pop','student pop', 'students poverty',\n",
    "                                                                                              'file','creation date'])\n",
    "poverty_districts = []\n",
    "\n",
    "\n",
    "for pp in range(len(poverty)):\n",
    "    district_name = poverty['district name'][pp]\n",
    "    name = district_name.rstrip('Public Schools')\n",
    "    poverty_districts.append(name)\n",
    "    \n",
    "pov_student_fraction = np.array(poverty['students poverty'])/np.array(poverty['student pop'])\n",
    "\n",
    "poverty_districts = np.array(poverty_districts)\n",
    "pov_student_fraction= np.array(pov_student_fraction)\n",
    "#print (poverty_districts)\n",
    "\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(20,10))\n",
    "ax1 = plt.axes() # add the axes\n",
    "ax1.set_aspect('equal')\n",
    "\n",
    "\n",
    "mypatches = []\n",
    "\n",
    "i = 0\n",
    "\n",
    "for shape in list(sf.iterShapes()):\n",
    "    \n",
    "    district = np.array(school_districts[i])\n",
    "    #print (district)\n",
    "    \n",
    "#    if (district == 'Colonial Beach Town'):\n",
    "#        district = 'Colonial Beach'\n",
    "#    if (district == 'James City County'):\n",
    "#        district = 'Williamsburg-James City County'\n",
    "#    if (district == 'Williamsburg City'):\n",
    "#        district = 'Williamsburg-James City County'\n",
    "#    if (district == 'West Point Town'):\n",
    "#        district = 'West Point'\n",
    "#    if (district == 'Fairfax City'):\n",
    "#        district = 'Fairfax County'\n",
    "#    if (district == 'Emporia City'):\n",
    "#        district = 'Greensville County'\n",
    "\n",
    "    #print (district)\n",
    "\n",
    "    array_match, = np.where(district == poverty_districts)\n",
    "       \n",
    "    if (len(array_match) == 1):\n",
    "        this_color= (pov_student_fraction[array_match][0] + np.nanmin(pov_student_fraction))/(np.nanmax(pov_student_fraction) - np.nanmin(pov_student_fraction))\n",
    "        #print (this_color)\n",
    "    if (len(array_match) == 0):\n",
    "        this_color= 0\n",
    "        print ('No State SOL data for', district)\n",
    "    \n",
    "    nparts = len(shape.parts) # total parts\n",
    "    if nparts == 1:\n",
    "        polygon = Polygon(shape.points)\n",
    "        patch = PolygonPatch(polygon, facecolor=plt.cm.Greens(this_color), zorder=2, ec='0.5')\n",
    "        ax1.add_patch(patch)\n",
    "        mypatches.append(patch)\n",
    "\n",
    "    else: # loop over parts of each shape, plot separately \n",
    "        for ip in range(nparts): # loop over parts, plot separately\n",
    "            i0=shape.parts[ip]\n",
    "            if ip < nparts-1:\n",
    "                i1 = shape.parts[ip+1]-1\n",
    "            else:\n",
    "                i1 = len(shape.points)\n",
    "\n",
    "            polygon = Polygon(shape.points[i0:i1+1])\n",
    "            patch = PolygonPatch(polygon, facecolor=plt.cm.Greens(this_color), zorder=2, ec='0.5')\n",
    "            ax1.add_patch(patch)\n",
    "            mypatches.append(patch)\n",
    "\n",
    "    i = i + 1\n",
    "\n",
    "over_district = np.where(pov_student_fraction == np.nanmax(pov_student_fraction))\n",
    "under_district, = np.where(pov_student_fraction == np.nanmin(pov_student_fraction))\n",
    "\n",
    "\n",
    "over_district_tick = pov_student_fraction[over_district][0]\n",
    "under_district_tick = pov_student_fraction[under_district][0]\n",
    "\n",
    "print (over_district_tick, under_district_tick)\n",
    "\n",
    "\n",
    "print (poverty_districts[over_district])\n",
    "\n",
    "\n",
    "\n",
    "over_district_label = poverty_districts[over_district][0]+' '+str(int(pov_student_fraction[over_district][0]*100))+'% in Poverty'\n",
    "under_district_label = poverty_districts[under_district][0]+' '+str(int(pov_student_fraction[under_district][0]*100))+'% in Poverty'\n",
    "\n",
    "p = PatchCollection(mypatches, cmap=plt.get_cmap('Greens'), alpha=1.0)\n",
    "p.set_array([0,0.5,1])\n",
    "\n",
    "cbar = fig.colorbar(p,orientation='horizontal', ticks=[0,1.], pad=0.02)\n",
    "cbar.set_ticklabels([under_district_label,over_district_label])\n",
    "cbar.ax.tick_params(labelsize=13)\n",
    "cbar.outline.set_visible(False)\n",
    "\n",
    "\n",
    "plt.xlim(-84,-75)\n",
    "plt.ylim(36.5,39.5)\n",
    "plt.axis('off')\n",
    "plt.title('Percent of students per district in Census defined poverty', fontsize=20)\n",
    "plt.savefig('poverty_map_va.jpg', dpi=180)\n",
    "plt.close()\n",
    "#plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
